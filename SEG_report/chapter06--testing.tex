\chapter{Testing}
\label{chap:testing}

This chapter looks at how we tested our platform, the tools we used, and what we learned from our testing approach.

\section{Approach and tools}
\label{sect:testing:approach}

We used a mix of automated and manual testing to check different parts of our application:

\subsection{Automated Testing}

\subsubsection{Unit Testing}
Unit tests formed the base of our testing strategy, checking individual components for validity. We used Django's built-in testing tools for the backend and Vitest for the frontend components.

\begin{itemize}
    \item \textbf{Backend Tests}: We wrote tests for models, serializers, views, and utility functions to verify they worked properly. These tests are structured in the \texttt{backend/api/tests} directory with a clear structure: separate subdirectories for views, models, and serializers, with each of these divided into test files for specific modules.
    
    \item \textbf{Frontend Tests}: We created tests for React components using Vitest and React Testing Library to check they rendered correctly. These tests sit in each directory in \texttt{frontend/src/pages}.
\end{itemize}

\subsubsection{API Integration Testing}
We wrote tests using the built-in testing tools provided by Django REST Framework, these can be separated into categories:

\begin{itemize}
    \item Tests that check authentication works properly
    \item Tests that verify data validation catches errors
    \item Tests for HTTP status codes and response formats
\end{itemize}

\subsubsection{Mock Testing}
We used the \texttt{unittest.mock} library to simulate parts of the system and test:

\begin{itemize}
    \item How the system handles errors when components fail
    \item Edge cases that would be hard to create in real conditions
\end{itemize}


\subsection{Manual Testing}

Some things were difficult to test automatically, so we checked them by hand:

\begin{itemize}
    \item \textbf{User Interaction}: Testing how users would move throughout the site
    \item \textbf{Visual Design}: Making sure everything fits the same style and conforms to accessibility standards while seeing if the interface was easy to understand and use
    \item \textbf{API endpoints}: We used Postman throughout development for quick manual testing of our API endpoints. This helped us verify endpoint behaviour during development before writing automated tests, and gave us an easy way to troubleshoot API issues when they arose.
\end{itemize}

\section{Quality assurance processes}
\label{sect:testing:process}

To keep our testing consistent, we used several approaches throughout development:

\subsection{Continuous Integration (CI)}

We set up GitHub Actions to run our tests automatically whenever we pushed code or created a pull request:

\begin{itemize}
    \item This highlighted problems that became a part of the main codebase
    \item Developers knew quickly if they broke something
    \item We kept a record of test results over time
\end{itemize}

The CI setup is in the \texttt{.github/workflows} directory.

\subsection{Code Review Process}

Our team reviews included checking test coverage:

\begin{itemize}
    \item New features needed accompanying tests
    \item We fixed failing tests when possible
    \item Reviewers checked test quality and coverage
\end{itemize}

\subsection{Test Coverage Monitoring}

We tracked test coverage using coverage.py for backend code and Vitest coverage reports for frontend code. We generated these reports occasionally and reviewed them to find areas needing more tests.

\section{Evaluation of testing}
\label{sect:testing:evaluation}

\subsection{What Worked Well}

Our testing approach had several strengths:

\begin{itemize}
    \item \textbf{Good API Coverage}: Our API tests gave us confidence that the backend worked correctly, with tests for all key endpoints.
    
    \item \textbf{Organised Test Structure}: Our tests mirrored the application structure, making them easy to find and maintain.
    
    \item \textbf{Thorough Authentication Testing}: We tested authentication for each endpoint to ensure system-wide security.
\end{itemize}

\subsection{Where We Could Improve}

Despite our efforts, we had some gaps:

\begin{itemize}
    \item \textbf{Frontend Test Coverage}: While we tested critical components, overall frontend test coverage was lower than backend coverage. We focused more on checking components rendered correctly than testing user interaction.
    
    \item \textbf{End-to-End Testing}: We didn't have automated tests for complete user journeys across the frontend and backend. We relied on manual testing for this but automated tests would have been better.
    
    \item \textbf{Performance Testing}: We didn't systematically test how the system would handle many users at once, which could be an issue for a university-wide platform.
\end{itemize}

\subsection{Coverage Results}

Our test coverage shows where our testing was effective and where it could improve:
 
\begin{itemize}
    \item \textbf{Backend Components}: 96\% coverage
    \item \textbf{Frontend Components}: 80\% branch coverage
\end{itemize}

\subsection{Balancing Automated and Manual Testing}

We used both automated and manual testing based on their strengths:

\begin{itemize}
    \item \textbf{Automated Testing Strengths}: Consistent, repeatable tests, testing at scale, catching regressions early, and documenting expected behaviour.
    
    \item \textbf{Automated Testing Limitations}: Complex to test rich UI interactions, and takes time to maintain as code changes.
    
    \item \textbf{Manual Testing Strengths}: Can evaluate usability, gives flexibility to explore unexpected paths, can check interface design, and might find issues automated tests miss.
    
    \item \textbf{Manual Testing Limitations}: Takes time, results vary between testers, limited coverage, and depends on tester focus.
\end{itemize}

We used manual testing mainly for things hard to automate. These included subjective quality checks, complex UI components, and interface design. Ideally, we would have automated more UI testing, especially for common user journeys, but time constraints limited this.

\subsection{Future Improvements}

Based on our experience, we would make these improvements in future projects:

\begin{itemize}
    \item Use tools for end-to-end testing of key user journeys
    \item Add regression testing to catch UI inconsistencies automatically
    \item Implement load and performance testing for critical endpoints
\end{itemize}

These changes would fill the main gaps in our testing approach while building on what we did well.